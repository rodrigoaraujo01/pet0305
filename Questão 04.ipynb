{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "Todos os métodos de aprendizado buscam encontrar estratégias matemáticas para reduzir o erro da função custo $f$.\n",
    "\n",
    "Para esta solução, será utilizada a seguinte nomenclatura:\n",
    "\n",
    "$$J(\\theta_i) = f_i$$\n",
    "\n",
    "$$\\nabla_i f(\\theta) = g_i = \\frac{df}{d\\theta_i} \\quad i \\in [1,n]$$\n",
    "\n",
    "$$H_{i,j} f(\\theta) = \\frac{\\partial^2f}{\\partial \\theta_i \\cdot \\partial \\theta_j} \\quad i,j \\in [1, n]$$\n",
    "\n",
    "$$\\textbf{H} =\n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} & \\dots  & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_n} \\\\\n",
    "    \\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_2^2} & \\dots  & \\frac{\\partial^2 f}{\\partial x_2 \\partial x_n} \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\frac{\\partial^2 f}{\\partial x_n \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_n \\partial x_2} & \\dots  & \\frac{\\partial^2 f}{\\partial x_m^2}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método do gradiente estocástico\n",
    "\n",
    "O método do gradiente estocástico é o método de aprendizado mais simples, porém tende a ser mais lento que os demais métodos. O algoritmo parte de um valor de pesos iniciais $w_0$ calculado e, até que os critérios de parada sejam atingidos, atualiza os pesos segundo a equação abaixo.\n",
    "\n",
    "$$\\theta_{i+1} = \\theta_i - g_i \\cdot \\epsilon_i \\quad i \\in [0, \\infty) $$\n",
    "\n",
    "O parâmetro $\\eta$ é a velocidade de treinamento e pode ser fixo ou encontrado através de algoritmos de otimização unidimensionais. \n",
    "\n",
    "Esse algoritmo é mais lento que os demais pois envolve múltiplas iterações até atingir um valor mínimo, mas é indicado para redes neurais muito grandes com milhares de parâmetros, visto que armazena apenas o vetor gradiente de tamanho $n$, e não faz uso da matriz Hessiana de tamanho $n^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo\n",
    "\n",
    "Definir sequência de aprendizado $\\epsilon_1, \\epsilon_2$<br>\n",
    "\n",
    "Definir o valor inicial de $\\theta$<br>\n",
    "\n",
    "Inicializar k com 1<br>\n",
    "\n",
    "Enquanto o critério de parada não for atingido, fazer {<br>\n",
    "\n",
    "$\\quad$ Selecionar um subconjunto do conjunto de treinamento $X$ com as respostas esperadas $y$\n",
    "\n",
    "$\\quad$ Calcular o gradiente: $g = \\frac{1}{m}\\nabla_\\theta \\sum_i L(f(x^{(i)};\\theta)y^{(i)})$<br>\n",
    "\n",
    "$\\quad$ Atualizar os pesos: $\\theta = \\theta - \\epsilon_k g$\n",
    "\n",
    "$\\quad$ Atualizar $k = k + 1$<br>\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de Newton\n",
    "\n",
    "O método de Newton é um algoritmo de segunda ordem porque faz uso da matriz Hessiana $\\textbf{H}$ e é mais rápido que o método do gradiente porque busca melhores direções de atualização dos pesos da rede.\n",
    "\n",
    "Considerando a aproximação quadrática da função $J$ com pesos iniciais $\\theta_0$ através da expansão de séries de Taylor:\n",
    "\n",
    "$$J(\\theta) = J(\\theta_0) + (\\theta - \\theta_0)^T \\nabla_{\\theta} J(\\theta_0) + \\frac{1}{2} (\\theta-\\theta_0)^T H(\\theta - \\theta_0)$$\n",
    "\n",
    "Resolvendo para o ponto crítico da função J, obtem-se a regra de atualização de parâmetros:\n",
    "\n",
    "$$\\theta^* = \\theta_0 - H^{-1} \\nabla_{\\theta} J(\\theta_0)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo\n",
    "\n",
    "Definir valor de $\\theta_0$<br>\n",
    "\n",
    "Definir conjunto de treino com $m$ exemplos<br>\n",
    "\n",
    "Enquanto o critério de parada não for atingido, fazer {<br>\n",
    "\n",
    "$\\quad$ Calcular o gradiente: $g = \\frac{1}{m}\\nabla_\\theta \\sum_i L(f(x^{(i)};\\theta)y^{(i)})$<br>\n",
    "\n",
    "$\\quad$ Calcular a Hessiana: $H = \\frac{1}{m}\\nabla^2_\\theta \\sum_i L(f(x^{(i)};\\theta)y^{(i)})$<br>\n",
    "\n",
    "$\\quad$ Calcular a inversa da Hessiana: $H^{-1}$<br>\n",
    "\n",
    "$\\quad$ Calcular a atualização: $\\Delta \\theta = -H^{-1}g$<br>\n",
    "\n",
    "$\\quad$ Atualizar os pesos: $\\theta = \\theta + \\Delta \\theta$\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos do gradiente conjugado\n",
    "\n",
    "O método do gradiente conjugado busca melhorar a performance do método do gradiente estocástico buscando uma direção de atualização que seja conjugada à direção anterior e não ortogonal como no método original.\n",
    "\n",
    "A nova direção de busca é calculada pela equação abaixo, onde o coeficiente $\\beta$ define quanto da direção anterior deve ser incluída na nova direção.\n",
    "\n",
    "$$d_t = \\nabla_\\theta J(\\theta) + \\beta_t d_{t-1}$$\n",
    "\n",
    "Matematicamente, a conjugação entre as direções é garantida se $d_t^T H d_{t-1} = 0$, porém, envolve o cálculo da Hessiana que é computacionalmente custoso.\n",
    "\n",
    "Utilizam-se então os métodos de Fletcher-Reeves ou de Polak_Ribière para calcular o valor de $\\beta_t$ sem que haja necessidade de calcular a Hessiana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo\n",
    "\n",
    "Definir valor de $\\theta_0$<br>\n",
    "\n",
    "Definir conjunto de treino com $m$ exemplos<br>\n",
    "\n",
    "Inicializar $\\rho_0 = 0$<br>\n",
    "\n",
    "Inicializar $g_0 = 0$<br>\n",
    "\n",
    "Inicializar $t = 1$<br>\n",
    "\n",
    "Enquanto o critério de parada não for atingido, fazer {<br>\n",
    "\n",
    "$\\quad$ Inicializar o gradiente: $g_t = 0$<br>\n",
    "\n",
    "$\\quad$ Calcular o gradiente: $g = \\frac{1}{m}\\nabla_\\theta \\sum_i L(f(x^{(i)};\\theta)y^{(i)})$<br>\n",
    "\n",
    "$\\quad$ Computar $\\beta_t$: $\\beta_t = \\frac{(g_t - g_{t-1})^T g_t}{g^T_{t-1}g_{t-1}}$<br>\n",
    "\n",
    "$\\quad$ Calcular a direção: $\\rho_t = -g_t+\\beta_t \\rho_{t-1}$<br>\n",
    "\n",
    "$\\quad$ Realizar busca linear para encontrar: $\\epsilon^* = argmin_\\epsilon \\frac{1}{m} \\sum_ {i=1}^m L(f(x^{(i)};\\theta_t + \\epsilon \\rho_t)y^{(i)})$<br>\n",
    "\n",
    "$\\quad$ Atualizar os pesos: $\\theta_{t+1} = \\theta_t + \\epsilon^* \\rho_t$<br>\n",
    "\n",
    "$\\quad$ $t = t+1$\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O método quase-Newton \n",
    "\n",
    "### Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
    "\n",
    "Este método busca obter algumas das vantagens do método de Newton, mas com menores custos computacionais. A ideia é aproximar a Hessiana $H$ através de uma matriz $M_t$ que pode ser melhorada iterativamente para se tornar uma boa representação de $H$.\n",
    "\n",
    "Uma vez que a matriz aproximada $M_t$ tenha sido determinada, a nova direção de busca $\\rho_t$ é calculada por $\\rho_t = M_t g_t$. Uma busca linear é realizada para determinar o tamanho do passo a ser dado $\\epsilon^*$ e a atualização dos parâmetros da rede é dada por:\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t + \\epsilon^* \\rho_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de Levemberg-Marquardt\n",
    "\n",
    "O método de Levemberg-Marquardt foi desenvolvido para trabalhar especificamente com funções custo que envolvem a soma de erros quadráticos. Para tal, ele não necessita do cálculo da Hessiana e é realizado com o cálculo do vetor gradiente e a matriz Jacobiana.\n",
    "\n",
    "Dada a função custo abaixo, onde m é a quantidade de características no vetor de entrada:\n",
    "\n",
    "$$F(\\theta) = \\sum\\limits_{i=0}^m e_i^2$$\n",
    "\n",
    "A matriz Jacobiana $J$ da função custo pode ser definida com base nas derivadas da função erro com em relação aos $n$ parâmetros da rede:\n",
    "\n",
    "$$J_{i,j} F(\\theta) = \\frac{d e_i}{d w_j} \\quad i \\in [1, m], \\quad j \\in [1, n]$$\n",
    "\n",
    "O gradiente da função custo pode então ser calculado com base no vetor de todos os erros $e$:\n",
    "\n",
    "$$ \\nabla F(\\theta) = 2 \\cdot J^T \\cdot e$$\n",
    "\n",
    "A matriz Hessiana pode então ser aproximada com:\n",
    "\n",
    "$$HF \\approx 2 J^T J + \\lambda I$$\n",
    "\n",
    "Onde $\\lambda$ representa o fator de amortecimento que garante a positividade da matriz Hessiana.\n",
    "\n",
    "Os novos parâmetros podem então ser recalculados segundo a fórmula:\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - (J_t^T J_t + \\lambda I)^{-1} \\cdot (wJ_t^T e_t)$$\n",
    "\n",
    "Quando o fator de amortecimento é zero, o método se iguala ao método de Newton e quando o fator é muito grande, o método se iguala ao gradiente estocástico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação entre os algoritmos\n",
    "\n",
    "![Comparação](img/algorithms_table_big.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "\n",
    "[Chapter 8. Optimization for training deep models](http://www.deeplearningbook.org/contents/optimization.html)\n",
    "\n",
    "[5 algorithms to train a neural network](https://www.neuraldesigner.com/blog/5_algorithms_to_train_a_neural_network)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
